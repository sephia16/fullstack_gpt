{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "template = PromptTemplate.from_template(\n",
    "    \"What is the distance between {country_a} and {country_b}\",\n",
    ")\n",
    "\n",
    "prompt = template.format(country_a = \"Mexico\", country_b = \"Thailand\")\n",
    "\n",
    "chat.predict(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected message type: AI. Use one of 'human', 'user', 'ai', 'assistant', or 'system'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb ì…€ 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m messages \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39;49mfrom_messages([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m    \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mYou are a geography expert. And you only reply in \u001b[39;49m\u001b[39m{language}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m    (\u001b[39m\"\u001b[39;49m\u001b[39mAI\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mCiao, mi chiamo \u001b[39;49m\u001b[39m{name}\u001b[39;49;00m\u001b[39m!.\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     (\u001b[39m\"\u001b[39;49m\u001b[39mhuman\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mWhat is the distance between \u001b[39;49m\u001b[39m{country_a}\u001b[39;49;00m\u001b[39m and \u001b[39;49m\u001b[39m{country_b}\u001b[39;49;00m\u001b[39m? Also, what is your name?\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sspringson/Desktop/fullstack-gpt/notebook.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m chat\u001b[39m.\u001b[39mpredict_messages(messages)\n",
      "File \u001b[0;32m~/Desktop/fullstack-gpt/env/lib/python3.11/site-packages/langchain/prompts/chat.py:541\u001b[0m, in \u001b[0;36mChatPromptTemplate.from_messages\u001b[0;34m(cls, messages)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    503\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_messages\u001b[39m(\n\u001b[1;32m    504\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m    505\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    506\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m    507\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[39m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m        a chat prompt template\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     _messages \u001b[39m=\u001b[39m [_convert_to_message(message) \u001b[39mfor\u001b[39;49;00m message \u001b[39min\u001b[39;49;00m messages]\n\u001b[1;32m    543\u001b[0m     \u001b[39m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     input_vars: Set[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/fullstack-gpt/env/lib/python3.11/site-packages/langchain/prompts/chat.py:541\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    503\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_messages\u001b[39m(\n\u001b[1;32m    504\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m    505\u001b[0m     messages: Sequence[MessageLikeRepresentation],\n\u001b[1;32m    506\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatPromptTemplate:\n\u001b[1;32m    507\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a chat prompt template from a variety of message formats.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[39m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m        a chat prompt template\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     _messages \u001b[39m=\u001b[39m [_convert_to_message(message) \u001b[39mfor\u001b[39;00m message \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m    543\u001b[0m     \u001b[39m# Automatically infer input variables from messages\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     input_vars: Set[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/fullstack-gpt/env/lib/python3.11/site-packages/langchain/prompts/chat.py:739\u001b[0m, in \u001b[0;36m_convert_to_message\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m    737\u001b[0m message_type_str, template \u001b[39m=\u001b[39m message\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(message_type_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 739\u001b[0m     _message \u001b[39m=\u001b[39m _create_template_from_message_type(message_type_str, template)\n\u001b[1;32m    740\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m     _message \u001b[39m=\u001b[39m message_type_str(prompt\u001b[39m=\u001b[39mPromptTemplate\u001b[39m.\u001b[39mfrom_template(template))\n",
      "File \u001b[0;32m~/Desktop/fullstack-gpt/env/lib/python3.11/site-packages/langchain/prompts/chat.py:700\u001b[0m, in \u001b[0;36m_create_template_from_message_type\u001b[0;34m(message_type, template)\u001b[0m\n\u001b[1;32m    698\u001b[0m     message \u001b[39m=\u001b[39m SystemMessagePromptTemplate\u001b[39m.\u001b[39mfrom_template(template)\n\u001b[1;32m    699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 700\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    701\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected message type: \u001b[39m\u001b[39m{\u001b[39;00mmessage_type\u001b[39m}\u001b[39;00m\u001b[39m. Use one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mai\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m'\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    704\u001b[0m \u001b[39mreturn\u001b[39;00m message\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected message type: AI. Use one of 'human', 'user', 'ai', 'assistant', or 'system'."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "   \n",
    "    (\"system\",\"You are a geography expert. And you only reply in {language}.\",),\n",
    "   (\"AI\",\"Ciao, mi chiamo {name}!.\"),\n",
    "    (\"human\",\"What is the distance between {country_a} and {country_b}? Also, what is your name?\"),\n",
    "])\n",
    "\n",
    "\n",
    "template.format_messages(\n",
    "    language = \"Greek\",\n",
    "    name = \"Socrates\",\n",
    "    country_a = \"Mexico\",\n",
    "    country_b = \"Thailand\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
